{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate for quick jupyter experiments\n",
    "import sys\n",
    "sys.path.append('/usr0/home/drschwar/src/paradigms')\n",
    "sys.path.append('/usr0/home/drschwar/src/subplot_artist')\n",
    "import socket\n",
    "import os\n",
    "import string\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "import mne\n",
    "import numpy\n",
    "from scipy.stats import boxcox\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "from matplotlib import gridspec, pyplot as plt\n",
    "from paradigms import Loader\n",
    "\n",
    "current_machine = socket.gethostname()\n",
    "current_machine = current_machine.lower() if current_machine is not None else ''\n",
    "\n",
    "if current_machine == 'drschwar-xps13':\n",
    "    data_root = r'C:\\Users\\danrs\\Documents\\BrainGroupData\\meg'\n",
    "    inv_path = os.path.join(\n",
    "        r'C:\\Users\\danrs\\Documents\\BrainGroupData\\meg', \n",
    "        '{experiment}' 'inv_{subject}_{experiment}_trans-D_nsb-5_cb-0_raw-{structural}-7-0.2-0.8-limitTrue-rankNone-inv.fif')\n",
    "    struct_dir = r'C:\\Users\\danrs\\Documents\\BrainGroupData\\meg\\structural' \n",
    "    session_stimuli_path = os.path.join(\n",
    "        r'C:\\Users\\danrs\\Documents\\BrainGroupData\\meg', \n",
    "        '{experiment}', '{subject}_sentenceBlock.mat')\n",
    "    word2vec_path = None\n",
    "    glove_path = None\n",
    "else:\n",
    "    data_root = '/share/volume0/newmeg/'\n",
    "    inv_path = '/share/volume0/newmeg/{experiment}/data/inv/{subject}/{subject}_{experiment}_trans-D_nsb-5_cb-0_raw-{structural}-7-0.2-0.8-limitTrue-rankNone-inv.fif'\n",
    "    struct_dir = '/share/volume0/drschwar/structural'\n",
    "    session_stimuli_path = '/share/volume0/newmeg/{experiment}/meta/{subject}/sentenceBlock.mat'\n",
    "    word2vec_path = '/share/volume0/language_representation/models/googlenews/GoogleNews-vectors-negative300.bin'\n",
    "    glove_path = '/share/volume0/drschwar/GloVe/glove.840B.300d.fmt_w2v.bin'\n",
    "    \n",
    "recording_tuple_regex = Loader.make_standard_recording_tuple_regex(\n",
    "    'trans-D_nsb-5_cb-0_empty-4-10-2-2_band-1-150_notch-60-120_beats-head-meas_blinks-head-meas')\n",
    "loader = Loader(session_stimuli_path, data_root, recording_tuple_regex, inv_path, struct_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_data(mne_raw, stimuli, time_before_stimulus=0.2, duration=3.0, picks=None):\n",
    "    \n",
    "    stimulus_data = list()\n",
    "    for index_stimulus in range(len(stimuli)):\n",
    "        start = stimuli[index_stimulus][Stimulus.time_stamp_attribute_name]\n",
    "        start_sample = numpy.searchsorted(mne_raw.times, start-time_before_stimulus)    \n",
    "        end_sample = int(start_sample + (duration + time_before_stimulus) * mne_raw.info['sfreq'])\n",
    "        data, times = mne_raw[:, start_sample:end_sample]\n",
    "        if picks is not None:\n",
    "            data = data[picks]\n",
    "        stimulus_data.append(data)\n",
    "        \n",
    "    stimulus_data = numpy.array(stimulus_data)\n",
    "    stimulus_data = numpy.mean(stimulus_data, axis=0)\n",
    "    grid = gridspec.GridSpec(1, 1)\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    axes = fig.add_subplot(grid[0, 0])\n",
    "    axes.matshow(stimulus_data, interpolation=None)\n",
    "    time = numpy.arange(int(-time_before_stimulus * mne_raw.info['sfreq']), int(duration * mne_raw.info['sfreq'])) / float(mne_raw.info['sfreq'])\n",
    "    for e in range(0, int(duration * mne_raw.info['sfreq']), int(0.5 * mne_raw.info['sfreq'])):\n",
    "        ev = e + time_before_stimulus * mne_raw.info['sfreq']\n",
    "        axes.axvline(ev, color='blue')\n",
    "        axes.axvline(ev + 50, color='red')\n",
    "    axes.set_xticklabels([time[int(t)] if 0 <= t < len(time) else t for t in axes.get_xticks()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing A\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing B\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing C\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing D\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing E\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing F\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing G\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing H\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "processing I\n",
      "loading block 1\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 2\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 3\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n",
      "loading block 4\n",
      "computing sources\n",
      "extracting time course\n",
      "getting 100ms slices\n"
     ]
    }
   ],
   "source": [
    "def _stimulus_to_100ms_slices(s):\n",
    "    return [(\n",
    "        (s['master_stimulus_index'], idx_time * 0.1), \n",
    "        s['time_stamp'] + 0.1 * idx_time) for idx_time in range(5)]\n",
    "\n",
    "def extract_stimuli_from_raw_time_courses(mne_raw, time_courses, stimuli, stimulus_to_name_time_pairs, num_samples):\n",
    "    names = list()\n",
    "    result = list()\n",
    "    for item in chain.from_iterable(map(stimulus_to_name_time_pairs, stimuli)):\n",
    "        if len(item) != 2:\n",
    "            raise ValueError('Expected stimulus_to_name_time_pairs to return a list of pairs for each '\n",
    "                             'stimulus. Are you returning just a single pair? Got: {}'.format(item))\n",
    "        name, time = item\n",
    "        sample_index = numpy.searchsorted(mne_raw.times, time, side='left')\n",
    "        result.append(numpy.expand_dims(time_courses[:, sample_index:(sample_index + num_samples)], 0))\n",
    "    return names, numpy.concatenate(result)   \n",
    "\n",
    "# picks = mne.pick_types(mne_raw.info, meg=True)\n",
    "# mne_raw.load_data()\n",
    "# plot_average_data(mne_raw, stimuli, time_before_stimulus=0.2, picks=picks)\n",
    "\n",
    "subject_labels = dict()\n",
    "subject_rois = dict()\n",
    "\n",
    "with mne.utils.use_log_level(False):\n",
    "\n",
    "    for subject in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']:\n",
    "\n",
    "        print('processing {}'.format(subject))\n",
    "\n",
    "        structurals = {\n",
    "            'A': 'struct4',\n",
    "            'B': 'struct5',\n",
    "            'C': 'struct6',\n",
    "            'D': 'krns5D',\n",
    "            'E': 'struct2',\n",
    "            'F': 'krns5A',\n",
    "            'G': 'struct1',\n",
    "            'H': 'struct3',\n",
    "            'I': 'krns5C'\n",
    "        }\n",
    "\n",
    "        inv, labels = loader.load_structural('harryPotter', subject, structurals[subject])\n",
    "        \n",
    "        roi_means = list()\n",
    "        for block in ['1', '2', '3', '4']:\n",
    "            print('loading block {}'.format(block))\n",
    "            mne_raw, stimuli, _ = loader.load_block('harryPotter', subject, block)\n",
    "            # According to the mne people, SNR of 1 (i.e. setting lambda2=1) is what you want for single trial data\n",
    "            # https://github.com/mne-tools/mne-python/issues/4131\n",
    "            print('computing sources')\n",
    "            source_estimate = mne.minimum_norm.apply_inverse_raw(mne_raw, inv, lambda2=1.0)\n",
    "            # time_course is (labels, time)\n",
    "            print('extracting time course')\n",
    "            time_course = source_estimate.extract_label_time_course(labels, inv['src'], mode='pca_flip', verbose=False)\n",
    "            source_estimate = None  # release memory\n",
    "            # time_course is now (num_keys, labels, 100)\n",
    "            print('getting 100ms slices')\n",
    "            keys, time_course = extract_stimuli_from_raw_time_courses(\n",
    "                mne_raw, time_course, stimuli, _stimulus_to_100ms_slices, 100)\n",
    "            # take the mean of the 100ms -> (num_keys, labels)\n",
    "            time_course = numpy.mean(time_course, axis=2)\n",
    "            roi_means.append(time_course)\n",
    "            \n",
    "\n",
    "#         epochs, keys = loader.load_epochs(\n",
    "#             'harryPotter', subject, ['1', '2', '3', '4'], _stimulus_to_100ms_slices, tmin=0, tmax=0.099, add_eeg_ref=False)\n",
    "\n",
    "#         # According to the mne people, SNR of 1 (i.e. setting lambda2=1) is what you want for single trial data\n",
    "#         # https://github.com/mne-tools/mne-python/issues/4131\n",
    "#         roi_means = list()\n",
    "#         for source_estimate in tqdm.tqdm(mne.minimum_norm.apply_inverse_epochs(\n",
    "#                 epochs, inv, lambda2=1.0, return_generator=True), \n",
    "#                 leave=False, total=len(keys), miniters=0):\n",
    "#             current_means = numpy.mean(\n",
    "#                 source_estimate.extract_label_time_course(labels, inv['src'], mode='mean', verbose=False), axis=1)\n",
    "#             roi_means.append(numpy.expand_dims(current_means, 0))\n",
    "\n",
    "        subject_rois[subject] = numpy.concatenate(roi_means, axis=0)\n",
    "        subject_labels[subject] = [label.name for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_subject_labels = None\n",
    "for subject in subject_labels:\n",
    "    if first_subject_labels is None:\n",
    "        first_subject_labels = subject_labels[subject]\n",
    "    else:\n",
    "        assert(numpy.array_equal(first_subject_labels, subject_labels[subject]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = sorted(subject_rois)\n",
    "rois = [subject_rois[subject] for subject in subjects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = [numpy.reshape(r, (r.shape[0] // 5, 5, -1)) for r in rois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5174, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n",
      "(5176, 5, 68)\n"
     ]
    }
   ],
   "source": [
    "for r in rois:\n",
    "    print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_stimuli = list()\n",
    "for s in subjects:\n",
    "    stimuli = list()\n",
    "    block_id = list()\n",
    "    for block in ['1', '2', '3', '4']:\n",
    "        _, block_stimuli, _ = loader.load_block('harryPotter', s, block)\n",
    "        block_id.extend([block] * len(block_stimuli))\n",
    "        stimuli.extend([b.text for b in block_stimuli])\n",
    "    all_stimuli.append((stimuli, block_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting at 1302\n",
      "inserting at 2653\n"
     ]
    }
   ],
   "source": [
    "# correct missing '+' stimuli for 'A'\n",
    "corrected = rois[0]\n",
    "for idx in range(max([len(s[0]) for s in all_stimuli])):\n",
    "    if all_stimuli[1][0][idx] == '+':\n",
    "        assert(s[0][idx] == '+' for s in all_stimuli[2:])\n",
    "        if all_stimuli[0][0][idx] != '+':\n",
    "            print('inserting at {}'.format(idx))\n",
    "            corrected_stimuli = all_stimuli[0][0][0:idx] + ['+'] + all_stimuli[0][0][idx:]\n",
    "            corrected_block_id = all_stimuli[0][1][0:idx] + [all_stimuli[0][1][idx - 1]] + all_stimuli[0][1][idx:]\n",
    "            all_stimuli[0] = corrected_stimuli, corrected_block_id\n",
    "            corrected = numpy.concatenate(\n",
    "                [corrected[0:idx], numpy.full((1,) + corrected.shape[1:], numpy.nan), corrected[idx:]])\n",
    "    assert(all([s[0][idx] == all_stimuli[0][0][idx] for s in all_stimuli[1:]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_subject in range(len(all_stimuli)):\n",
    "    all_stimuli[idx_subject] = all_stimuli[idx_subject][0], [int(b) for b in all_stimuli[idx_subject][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois[0] = corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "print(all_stimuli[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = numpy.concatenate([numpy.expand_dims(r, 0) for r in rois], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5176, 5, 68)\n"
     ]
    }
   ],
   "source": [
    "print(rois.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = numpy.transpose(rois, axes=(0, 1, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 5176, 68, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savez(\n",
    "    '/usr0/home/drschwar/src/ulmfit_data/harry_potter_pca.npz',\n",
    "    stimuli=numpy.array(all_stimuli[0][0]),\n",
    "    blocks=numpy.array(all_stimuli[0][1], dtype=numpy.int64),\n",
    "    rois=numpy.array(first_subject_labels),\n",
    "    subjects=numpy.array(subjects),\n",
    "    data=rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_raw, stimuli, _ = loader.load_block('harryPotter', 'A', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.load('/usr0/home/drschwar/src/ulmfit_data/harry_potter_pca.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2.50855019, 4.62644884, 3.11857033, 2.66599053, 2.0550925 ],\n",
       "         [1.88327035, 2.2761118 , 1.71844959, 1.53066243, 1.27884711],\n",
       "         [1.87729142, 1.39619447, 2.14151152, 1.57469817, 1.92370568],\n",
       "         ...,\n",
       "         [2.65242209, 1.73760765, 3.42613867, 2.45927217, 3.62275474],\n",
       "         [2.74493767, 4.02696994, 3.49896798, 2.93642855, 2.74324888],\n",
       "         [1.91200418, 2.49459163, 1.7264115 , 2.4108514 , 1.57914565]],\n",
       "\n",
       "        [[1.391914  , 2.18727557, 3.25229419, 2.61531819, 2.63281145],\n",
       "         [1.68505411, 1.445136  , 1.87278115, 1.15040324, 1.3474002 ],\n",
       "         [1.78733592, 1.41656226, 1.4776016 , 1.66545329, 1.49950228],\n",
       "         ...,\n",
       "         [3.10360542, 1.60999585, 3.72334601, 3.31970575, 2.83481224],\n",
       "         [2.31270869, 2.71260624, 3.22678335, 3.01674638, 2.3585981 ],\n",
       "         [1.77200711, 1.78594323, 2.13122096, 2.20889252, 1.76494783]],\n",
       "\n",
       "        [[2.09914668, 2.38242514, 3.56007668, 1.976317  , 3.66097077],\n",
       "         [1.25402798, 1.30874499, 1.7835789 , 1.90595538, 3.02560258],\n",
       "         [1.30316829, 2.34211934, 1.94119698, 1.6710921 , 2.14243306],\n",
       "         ...,\n",
       "         [1.72083597, 1.47335297, 4.02950067, 2.54961516, 1.44435501],\n",
       "         [2.20917036, 2.47583592, 3.15883316, 2.2677823 , 3.28561083],\n",
       "         [1.79432355, 2.01758734, 1.7368806 , 1.4376273 , 2.18515096]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.83730589, 1.98550765, 2.27009073, 3.0711569 , 3.55669633],\n",
       "         [1.71870086, 1.86659772, 1.77237932, 1.96281915, 2.16790114],\n",
       "         [1.81132565, 1.77544239, 1.72592471, 1.80119485, 1.43524972],\n",
       "         ...,\n",
       "         [1.57457369, 1.90246497, 1.17581263, 2.32374259, 2.20271254],\n",
       "         [2.13700899, 2.38561873, 2.32107356, 2.8635276 , 2.71636025],\n",
       "         [1.89177479, 1.77802224, 1.76413963, 2.09869136, 2.42619673]],\n",
       "\n",
       "        [[3.54461872, 2.85853977, 3.26599354, 2.15907642, 2.86090569],\n",
       "         [2.70877449, 1.87784125, 1.7965736 , 1.78867045, 2.37352974],\n",
       "         [1.80488903, 1.86785658, 1.62448269, 2.07718569, 1.71640047],\n",
       "         ...,\n",
       "         [1.63844274, 2.27839167, 1.14322708, 1.23009654, 2.16250589],\n",
       "         [2.69643265, 3.03112781, 4.25918647, 2.43403301, 2.98758989],\n",
       "         [2.20537738, 2.03761688, 1.63805459, 1.90539013, 2.27249362]],\n",
       "\n",
       "        [[2.76275589, 2.17773604, 2.658799  , 3.40395554, 2.87723069],\n",
       "         [1.92515547, 1.96952423, 0.99401308, 1.9382779 , 1.23702519],\n",
       "         [1.55151529, 2.29958955, 1.52094152, 1.47307357, 2.1783404 ],\n",
       "         ...,\n",
       "         [1.9803231 , 1.91663093, 1.61307403, 2.26908867, 2.37879628],\n",
       "         [2.25526639, 2.5906697 , 2.10515534, 3.01679426, 1.98058086],\n",
       "         [2.05579248, 1.82284516, 1.68630265, 2.0604125 , 1.78710989]]],\n",
       "\n",
       "\n",
       "       [[[1.99027689, 3.86917781, 2.05188018, 2.17286909, 1.94482148],\n",
       "         [1.44025251, 3.27702263, 1.9374268 , 2.02777878, 1.70801985],\n",
       "         [1.91715954, 2.13967346, 2.05001038, 2.75083196, 2.45456892],\n",
       "         ...,\n",
       "         [2.00146908, 2.28416657, 1.88041993, 2.75557188, 2.49987404],\n",
       "         [1.31795136, 2.10853943, 1.85318375, 1.8222052 , 2.14068863],\n",
       "         [2.11490469, 3.9728813 , 2.07845657, 2.58257317, 3.09394837]],\n",
       "\n",
       "        [[2.151757  , 2.0238221 , 1.92522517, 1.54769683, 1.51743986],\n",
       "         [1.70834315, 1.60626063, 2.35814678, 1.40490275, 1.54934012],\n",
       "         [2.39667174, 2.65673915, 2.06941951, 1.70993504, 1.41735967],\n",
       "         ...,\n",
       "         [1.86951644, 2.49312343, 2.28580374, 2.16549509, 1.96961284],\n",
       "         [1.81565123, 1.41375033, 1.79908297, 1.59878056, 1.53184213],\n",
       "         [2.25951288, 2.02430324, 3.23734031, 1.94105282, 1.51565904]],\n",
       "\n",
       "        [[1.66609543, 2.39187348, 1.65064485, 2.45605438, 2.18942381],\n",
       "         [1.61452637, 2.07778988, 1.33582103, 2.06903462, 2.00645368],\n",
       "         [1.87820591, 1.32969   , 1.71091502, 1.86517071, 1.86770222],\n",
       "         ...,\n",
       "         [1.84738049, 1.73139442, 1.42068102, 2.02666421, 1.38957562],\n",
       "         [1.58772433, 1.57037173, 1.56229299, 1.84248344, 2.09184618],\n",
       "         [1.71666375, 2.41687656, 1.54234477, 2.2175925 , 2.51343547]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.54752472, 2.6186014 , 3.4075342 , 2.21908005, 3.35095276],\n",
       "         [2.44659017, 2.57283269, 2.67027926, 2.14398853, 2.07799405],\n",
       "         [2.94692088, 3.55012786, 3.16634196, 2.70276887, 4.0860745 ],\n",
       "         ...,\n",
       "         [2.07073964, 2.9010195 , 3.00316468, 2.16835301, 2.14485518],\n",
       "         [2.35493417, 2.49513684, 3.1891858 , 2.10551146, 2.79903557],\n",
       "         [1.89017345, 3.34943455, 2.71323964, 2.37838043, 1.84731299]],\n",
       "\n",
       "        [[3.1629318 , 3.07312807, 2.45830374, 3.32646226, 3.0040596 ],\n",
       "         [2.72523539, 1.82161942, 2.58369753, 2.4193057 , 1.89804577],\n",
       "         [2.88927627, 2.49263161, 2.26078453, 2.55271506, 1.92282799],\n",
       "         ...,\n",
       "         [1.55211284, 1.89937027, 1.8785011 , 1.61506017, 2.33394857],\n",
       "         [2.81201927, 1.92527499, 1.91822036, 1.6514862 , 2.27295488],\n",
       "         [2.78823999, 2.30211507, 2.99204348, 2.33127021, 2.51176853]],\n",
       "\n",
       "        [[2.66764403, 2.71877632, 1.71951324, 1.91206376, 3.24288317],\n",
       "         [2.17417855, 1.42476439, 2.44247619, 1.68290305, 1.65334501],\n",
       "         [2.24050583, 1.82011929, 2.80485261, 2.21412036, 2.64067107],\n",
       "         ...,\n",
       "         [1.34084073, 1.42250078, 1.64323548, 1.60624814, 2.10317073],\n",
       "         [2.54569808, 2.12843935, 1.61302924, 1.76323493, 2.72864371],\n",
       "         [2.50052565, 1.95806723, 2.58543752, 2.26472685, 1.97785591]]],\n",
       "\n",
       "\n",
       "       [[[1.79470427, 1.92045735, 1.21611979, 1.48597259, 1.34753184],\n",
       "         [1.35660608, 2.54469305, 2.18469541, 2.15808227, 1.39571072],\n",
       "         [0.94437032, 1.45922304, 0.92362175, 0.83911429, 0.97752827],\n",
       "         ...,\n",
       "         [1.27481497, 1.12682324, 0.80074494, 1.23267359, 1.0221398 ],\n",
       "         [1.76460622, 1.98021689, 1.57248861, 1.5181156 , 1.59189104],\n",
       "         [0.94510133, 1.74594981, 1.39879117, 1.53783251, 1.98133981]],\n",
       "\n",
       "        [[1.20652897, 0.98224637, 1.21423249, 0.97663428, 1.25087454],\n",
       "         [1.08164871, 1.43856523, 1.95889253, 1.33952046, 1.64474574],\n",
       "         [0.84320308, 0.90535212, 0.90954558, 1.15877931, 1.02692173],\n",
       "         ...,\n",
       "         [0.8805536 , 1.12237384, 1.16241269, 0.98774632, 1.30511405],\n",
       "         [1.3594043 , 1.13594927, 1.27749921, 1.02804785, 0.94095828],\n",
       "         [0.83631463, 1.48300533, 2.25670092, 1.18992113, 1.41489664]],\n",
       "\n",
       "        [[1.21414396, 0.95667802, 1.36123965, 1.92720038, 1.34243234],\n",
       "         [1.92449441, 1.80617464, 1.70945399, 1.81351677, 1.19957947],\n",
       "         [1.00314381, 1.09621746, 1.04406994, 0.90220026, 0.92586512],\n",
       "         ...,\n",
       "         [1.26390469, 0.9755225 , 1.14418946, 0.92042127, 0.80608517],\n",
       "         [0.99475591, 1.15317187, 1.41910877, 1.79981528, 1.60396227],\n",
       "         [1.25679191, 1.3109458 , 1.75650279, 1.29691042, 1.27800097]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.48756267, 2.04412045, 2.26020512, 1.84488327, 2.40932121],\n",
       "         [2.00070916, 2.13893578, 1.81807286, 2.09957417, 2.17372809],\n",
       "         [1.04048692, 1.20236208, 1.29166478, 1.26465614, 1.17891663],\n",
       "         ...,\n",
       "         [1.48622886, 1.41609046, 1.15249458, 1.29511319, 1.1575794 ],\n",
       "         [2.09950284, 1.58751661, 2.3616982 , 1.62738458, 2.04012266],\n",
       "         [1.76141935, 1.75749993, 2.28680069, 1.69627781, 2.2004571 ]],\n",
       "\n",
       "        [[2.28847162, 1.53543193, 1.97077183, 2.00608662, 1.83033875],\n",
       "         [2.18548187, 2.17094614, 1.62054118, 2.43993714, 2.07407943],\n",
       "         [1.26608845, 1.24448331, 1.19305665, 0.97843985, 1.37384766],\n",
       "         ...,\n",
       "         [1.16358074, 1.49054583, 1.4617314 , 1.39100599, 1.01092602],\n",
       "         [2.16810218, 1.46382709, 1.57617274, 1.88665823, 1.60701975],\n",
       "         [2.0298602 , 2.00880406, 1.19445166, 2.17247266, 1.92955885]],\n",
       "\n",
       "        [[1.73321211, 2.14099482, 1.76075054, 1.35555813, 2.2295891 ],\n",
       "         [2.10061616, 2.29580159, 1.99168847, 2.16736769, 1.46802682],\n",
       "         [1.0749021 , 1.35008018, 1.45966553, 0.98420387, 1.22627912],\n",
       "         ...,\n",
       "         [1.49896709, 1.56064269, 1.34798332, 0.92062588, 1.07907848],\n",
       "         [1.54482896, 1.90495363, 1.75766404, 1.34854994, 1.65223459],\n",
       "         [2.06598596, 2.35931257, 1.3207788 , 1.69577626, 1.5998499 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.34305778, 1.6152126 , 1.34540329, 1.65520355, 2.00052135],\n",
       "         [1.59192988, 2.26803552, 1.43184032, 1.601003  , 2.08468895],\n",
       "         [1.49481651, 1.57746115, 1.25195686, 1.15417068, 1.31110385],\n",
       "         ...,\n",
       "         [1.89479061, 2.28479496, 1.38243337, 1.58801827, 1.43972498],\n",
       "         [1.49526238, 1.91527765, 1.61067917, 1.60887964, 2.47826301],\n",
       "         [2.13966538, 2.2970847 , 1.42254315, 1.72706489, 1.84765577]],\n",
       "\n",
       "        [[1.08640339, 1.39214805, 1.85381864, 1.27067682, 1.30638538],\n",
       "         [2.06357409, 1.88938471, 3.05676675, 1.60523746, 1.3694596 ],\n",
       "         [1.30306422, 1.32945383, 1.55006814, 1.42728963, 1.2087048 ],\n",
       "         ...,\n",
       "         [1.45272457, 1.81689538, 2.64554194, 1.77632741, 1.65494874],\n",
       "         [1.64816753, 1.90673271, 2.13926617, 1.56450859, 1.6881493 ],\n",
       "         [2.60351301, 1.72703143, 2.67753634, 1.50674621, 1.40709078]],\n",
       "\n",
       "        [[1.33876337, 1.33991625, 1.50182452, 0.86949709, 1.2116245 ],\n",
       "         [1.75390574, 1.60526473, 1.72967871, 1.76908087, 1.3647213 ],\n",
       "         [1.42375018, 1.12529109, 1.07468019, 1.03232596, 1.2455709 ],\n",
       "         ...,\n",
       "         [1.26573301, 0.99524415, 1.03312954, 1.77400928, 2.28314498],\n",
       "         [1.61696547, 1.34793196, 2.27970469, 1.4359925 , 1.18731115],\n",
       "         [1.74136385, 1.36732061, 1.68380128, 1.68263019, 1.59664914]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.58225031, 1.60705054, 1.5025716 , 1.42063815, 1.80652944],\n",
       "         [2.2798327 , 1.97479749, 1.85305922, 1.49853793, 1.70628839],\n",
       "         [1.58868578, 1.50283841, 1.48701012, 1.42440339, 1.54871608],\n",
       "         ...,\n",
       "         [1.68589751, 1.75813886, 1.03543663, 1.39377019, 1.80788796],\n",
       "         [2.74104276, 1.66139238, 2.37356956, 2.03580651, 2.36609068],\n",
       "         [2.73364697, 1.93605855, 2.4563213 , 1.66013369, 1.91136865]],\n",
       "\n",
       "        [[2.37209149, 2.79774209, 1.97264729, 3.01880917, 2.75685732],\n",
       "         [2.59654926, 3.04910245, 2.58381729, 2.6850022 , 2.98133351],\n",
       "         [1.78769771, 1.57181195, 2.04044565, 2.78056494, 1.64056534],\n",
       "         ...,\n",
       "         [1.2147206 , 1.52178224, 1.76577388, 2.04589308, 2.44394009],\n",
       "         [2.47225629, 3.53518322, 2.93131403, 2.63418138, 3.84638802],\n",
       "         [3.04547963, 3.49138891, 2.46749597, 3.50481189, 3.55110105]],\n",
       "\n",
       "        [[2.18902019, 2.25212704, 1.66608704, 1.53577738, 1.60306407],\n",
       "         [2.42462985, 2.07485987, 1.90897763, 1.94822477, 2.23404792],\n",
       "         [2.31848764, 2.0258959 , 1.86104511, 1.83379375, 1.59951389],\n",
       "         ...,\n",
       "         [1.52692057, 1.52771322, 1.51442234, 2.17741665, 1.56413934],\n",
       "         [2.92774945, 3.01979429, 2.39664018, 1.81861291, 1.96066961],\n",
       "         [3.49098889, 2.40623025, 2.07597876, 2.564282  , 2.54381234]]],\n",
       "\n",
       "\n",
       "       [[[1.34094693, 1.37007415, 2.51517979, 1.79980733, 0.84502115],\n",
       "         [1.239136  , 1.93778903, 2.59584163, 1.85031925, 1.43617643],\n",
       "         [1.07069203, 1.53135478, 1.43130717, 1.40840642, 1.16702914],\n",
       "         ...,\n",
       "         [1.36420473, 1.54402349, 1.32789275, 1.37102083, 1.12825656],\n",
       "         [1.29092441, 1.44894122, 2.64021056, 1.5930026 , 1.0049456 ],\n",
       "         [1.50626121, 2.19243179, 2.53674612, 2.04494778, 2.03002207]],\n",
       "\n",
       "        [[1.26258361, 1.34901886, 1.30596474, 1.70088673, 1.53296022],\n",
       "         [1.18692401, 1.19606637, 1.19540657, 1.4671017 , 1.10890354],\n",
       "         [0.99136822, 1.004481  , 1.2945938 , 1.02534894, 0.97252895],\n",
       "         ...,\n",
       "         [1.19878227, 1.07771904, 0.9011668 , 1.71458969, 0.99738803],\n",
       "         [1.15018065, 1.13003363, 1.05298496, 1.39911087, 1.1279303 ],\n",
       "         [1.6670694 , 1.55622742, 1.25599362, 1.28602804, 1.59370416]],\n",
       "\n",
       "        [[1.65448688, 1.2448318 , 1.26562182, 1.11697367, 1.44772405],\n",
       "         [1.50256742, 1.47833977, 1.50508091, 1.20520275, 1.20221061],\n",
       "         [1.124569  , 1.18220919, 1.10064507, 0.89523493, 1.17020839],\n",
       "         ...,\n",
       "         [1.58029587, 1.07602702, 1.17429218, 1.18475544, 1.06883838],\n",
       "         [1.35874671, 1.35537398, 0.87860423, 0.92749074, 1.17728295],\n",
       "         [1.58989117, 1.49396774, 1.66618392, 1.51391353, 1.69013503]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.31946801, 1.42246891, 1.24849518, 1.41851314, 1.7847644 ],\n",
       "         [2.0052057 , 1.26872139, 1.47408339, 1.58549578, 1.29649406],\n",
       "         [1.15358411, 1.474071  , 1.40549342, 1.26973398, 1.33382229],\n",
       "         ...,\n",
       "         [1.50935025, 1.56732605, 1.09120491, 1.55392266, 1.3742521 ],\n",
       "         [0.98273781, 1.24525458, 1.4719577 , 1.22656193, 1.47445687],\n",
       "         [2.05213548, 1.72165388, 1.58912449, 1.69896551, 1.82461189]],\n",
       "\n",
       "        [[1.86221939, 1.5398599 , 1.58344854, 1.00673391, 0.98276199],\n",
       "         [1.93418106, 1.6399327 , 1.32674373, 1.4166331 , 1.43135419],\n",
       "         [1.10981355, 1.20217065, 1.26490587, 1.03907332, 1.0541965 ],\n",
       "         ...,\n",
       "         [1.05731173, 1.42081687, 1.07834699, 1.39224366, 0.96406452],\n",
       "         [1.44152925, 1.09913633, 1.21602762, 1.07005746, 0.9707745 ],\n",
       "         [2.01052615, 1.83814774, 1.32239269, 1.68865262, 1.44195593]],\n",
       "\n",
       "        [[0.95509175, 1.1982834 , 0.98844364, 1.23229961, 1.4693947 ],\n",
       "         [1.48045754, 1.5742742 , 1.50323393, 1.70816283, 1.79937149],\n",
       "         [0.95898946, 1.06777636, 1.41398435, 1.00080197, 1.14207738],\n",
       "         ...,\n",
       "         [1.22415396, 1.58684364, 1.09096902, 1.59635545, 1.17312891],\n",
       "         [0.92505143, 0.77594292, 1.14366962, 1.07510765, 1.36463329],\n",
       "         [1.53883873, 1.55693749, 1.76034878, 1.68616132, 2.06503183]]],\n",
       "\n",
       "\n",
       "       [[[2.18143112, 1.50481172, 1.62010614, 2.56051855, 1.6590061 ],\n",
       "         [2.34786563, 1.94510673, 1.72335359, 1.4647138 , 1.78138301],\n",
       "         [1.51701942, 1.93860881, 1.87095293, 2.01031481, 1.79695578],\n",
       "         ...,\n",
       "         [1.91145381, 1.70304582, 1.83524182, 2.10469586, 1.19921209],\n",
       "         [3.01109461, 2.32645821, 1.91339073, 3.3235434 , 2.39024957],\n",
       "         [2.52722686, 2.60306356, 2.49571578, 2.0436923 , 2.09448095]],\n",
       "\n",
       "        [[1.70470526, 2.00316284, 1.50798281, 1.72635651, 1.64589307],\n",
       "         [1.55974086, 1.48790074, 1.71511292, 1.81796604, 1.89561527],\n",
       "         [1.54861607, 1.4739254 , 1.6157498 , 1.62019408, 1.37823413],\n",
       "         ...,\n",
       "         [1.43175418, 1.62699803, 1.55105771, 1.41467834, 1.35412735],\n",
       "         [2.52399249, 2.12177328, 1.78268677, 2.29499014, 1.87463999],\n",
       "         [1.64849029, 2.07296641, 1.64158512, 1.4612764 , 1.53162601]],\n",
       "\n",
       "        [[1.80985329, 2.06789972, 1.44751415, 1.45646475, 1.62705788],\n",
       "         [1.38772516, 2.40232999, 1.23623774, 1.75405424, 3.07742503],\n",
       "         [1.73622781, 1.88704405, 1.56034221, 1.38475046, 1.89921914],\n",
       "         ...,\n",
       "         [1.3180532 , 1.3676353 , 1.33764479, 1.63121237, 2.37775282],\n",
       "         [1.7350308 , 3.15092626, 2.05907936, 2.04502082, 1.99587466],\n",
       "         [1.56129591, 1.74048059, 1.4917946 , 1.99008354, 2.46406444]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.28794445, 2.27265758, 2.02872031, 2.08782791, 1.87813186],\n",
       "         [2.17926038, 1.85492518, 1.82559063, 1.58442007, 2.34229292],\n",
       "         [1.91780278, 1.51594515, 1.3056644 , 2.01120384, 1.22753159],\n",
       "         ...,\n",
       "         [1.46990679, 1.75746886, 1.65450599, 1.51876165, 1.30782419],\n",
       "         [1.83883603, 2.7378968 , 3.12149648, 2.24038854, 2.51409947],\n",
       "         [2.27638732, 1.48489956, 1.74232789, 1.8224411 , 1.66622844]],\n",
       "\n",
       "        [[1.52704497, 2.08763867, 1.96135336, 2.12703063, 1.82377906],\n",
       "         [2.71179277, 1.69815098, 1.67147826, 1.83755628, 2.36970424],\n",
       "         [1.7168855 , 1.81468275, 1.90651215, 1.64939574, 2.36914471],\n",
       "         ...,\n",
       "         [1.1971272 , 2.20579235, 1.90506346, 1.66898125, 2.08245968],\n",
       "         [1.85381055, 2.30634642, 2.78986958, 1.91161715, 2.12949531],\n",
       "         [2.58234732, 1.54513898, 2.13997272, 2.24123889, 1.72635972]],\n",
       "\n",
       "        [[1.78594202, 1.44269666, 1.54763144, 1.82627601, 1.57260311],\n",
       "         [2.52535959, 1.80826266, 1.6213709 , 2.06507511, 2.10387193],\n",
       "         [1.6016723 , 1.72618734, 1.4163599 , 1.63424347, 1.9274394 ],\n",
       "         ...,\n",
       "         [1.76246192, 2.1670504 , 2.0091167 , 1.40284885, 1.96565029],\n",
       "         [1.79982019, 1.94478596, 1.57847966, 1.71506379, 2.05689594],\n",
       "         [2.14905578, 2.22866176, 2.36952302, 1.65009348, 2.79312921]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
